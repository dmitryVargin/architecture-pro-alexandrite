# Архитектурное решение по логированию в системе «Александрит»

## 1. Сбор логов и уровни логирования

Для эффективного анализа нам необходимо собирать логи со всех серверных компонентов (**Shop API**, **CRM API**, **MES API**) и брокера сообщений.

### Список необходимых логов (уровень `INFO`)

Эти логи фиксируют успешные бизнес-события для отслеживания «пути» заказа:

*   **Изменение статуса заказа:** `[timestamp] [INFO] [order_id] [customer_id] Status changed from {old_status} to {new_status}.`
*   **Загрузка 3D-модели:** `[timestamp] [INFO] [order_id] File uploaded: {file_name}, size: {size}, type: {extension}.`
*   **Расчет в MES:** `[timestamp] [INFO] [order_id] Calculation started. Complexity: {polygons} polygons.`
*   **Взаимодействие с очередью:** `[timestamp] [INFO] [order_id] Message sent to queue {queue_name} with routing_key {key}.`
*   **Авторизация API-партнера:** `[timestamp] [INFO] [partner_id] API request received: {endpoint_name}.`

### Другие уровни логирования

*   **DEBUG:** Используется только в `dev` и `release` окружениях. Логируем детальные шаги алгоритма расчета стоимости в **MES** и параметры SQL-запросов. В `prod` выключен для экономии места.
*   **WARN:** Нештатные, но не критичные ситуации. Например: «Превышено время ожидания ответа от **RabbitMQ**, повторная попытка №2» или «Загружен файл подозрительно большого размера».
*   **ERROR:** Ошибки, требующие внимания. Например: «Не удалось сохранить файл в **S3**», «Ошибка валидации 3D-модели», «БД недоступна». К логу обязательно прикладывается **StackTrace**.
*   **FATAL:** Критические сбои, после которых сервис не может продолжать работу (например, ошибка при чтении конфигов при старте).

## 2. Мотивация

Логирование превращает «догадки» службы поддержки в «факты». Вместо того чтобы верить клиенту на слово, мы видим реальную цепочку событий.

**Влияние на метрики:**

*   **Mean Time to Acknowledge (MTTA):** Сокращение времени первичной реакции поддержки.
*   **SLA по инцидентам:** Увеличение доли проблем, решенных в течение первого часа.
*   **Cost per Ticket:** Снижение стоимости обработки одного обращения клиента за счет быстрой диагностики.
*   **Success Rate заказов:** Возможность проактивно находить ошибки до того, как клиент о них сообщит.

## 3. Приоритизация внедрения

Мы не можем внедрить всё сразу, поэтому фокус на первом этапе:

1.  **MES API (C#):** Это «черный ящик», где происходит самая сложная работа. Ошибки в расчетах — главная причина недовольства.
2.  **API Интеграции (Shop/CRM):** Чтобы подтвердить или опровергнуть факт потери сообщений в **RabbitMQ**.
3.  **Остальные системы:** По остаточному принципу.

**Почему сначала логирование, а потом трейсинг?** Логи дают детальную информацию об ошибке внутри одного сервиса (почему упало), а трейсинг — только место (где упало). Для текущих проблем «Александрита» понимание причин ошибок важнее визуализации путей.

## 4. Предлагаемое решение (Стек PLG: Promtail + Loki + Grafana)

Я предлагаю использовать **Grafana Loki**, так как он дешевле в хранении, чем ELK, и идеально интегрируется с уже выбранной нами Grafana.

**Компоненты:**

*   **Promtail** (или **Fluent Bit**): Агенты на каждом EC2-инстансе, которые «читают» файлы логов и отправляют их в центральное хранилище.
*   **Grafana Loki:** База данных, оптимизированная для хранения логов.
*   **Grafana:** Единый интерфейс, где можно одновременно видеть и графики нагрузки (метрики), и текст логов.

## 5. Политика безопасности и хранения

### Безопасность

*   **Маскирование PII:** На уровне приложения (через библиотеки логирования) настраиваются фильтры, которые заменяют номера карт, пароли и email-адреса на `***`.
*   **Доступ:** Логи уровня `INFO` доступны поддержке и разработчикам. Логи с деталями транзакций — только Senior-разработчикам и DevOps.
*   **Аудит:** Все действия пользователей в самой системе логирования (кто и что искал) фиксируются.

### Хранение

*   **Индексация:** Отдельные индексы (streams) для каждого сервиса: `app=mes`, `app=crm`, `app=shop`.
*   **Retention (Срок хранения):**
    *   `INFO`/`WARN` — 30 дней (достаточно для разбора большинства жалоб).
    *   `ERROR`/`FATAL` — 90 дней (для анализа долгосрочных трендов).
*   **Размер:** Ограничение объема в 500 ГБ на всё хранилище. При достижении лимита старые логи затираются (FIFO).

## 6. Анализ логов и алертинг

Система сбора превращается в систему анализа через следующие механизмы:

*   **Алертинг по частоте ошибок:** Если в течение 1 минуты появилось более 50 логов уровня `ERROR` от **MES API**, отправляется алерт «Critical Failure in MES» в Telegram.
*   **Поиск аномалий:** Настройка Grafana-алертов на резкое изменение количества логов `order_created`. Если их стало в 10 раз больше обычного — возможна атака или баг бескочного цикла.
*   **Логирование задержек:** Если лог `Calculation completed` содержит значение `duration > 30 min`, это событие попадает на отдельный дашборд для продакт-менеджера.

## 7. Дополнительное задание: Выбор технологии

Для выбора между **ELK** (Elasticsearch) и **PLG** (Loki) использовались следующие критерии:

| Критерий | ELK (Elasticsearch) | PLG (Grafana Loki) | Почему это важно для «Александрита» |
| :--- | :--- | :--- | :--- |
| **Стоимость хранения** | Высокая (индексирует весь текст) | Низкая (индексирует только метаданные) | У нас линейный рост заказов, данных будет очень много. |
| **Сложность поддержки** | Высокая (нужен отдельный спец по Elastic) | Низкая (проще в эксплуатации) | У нас всего один DevOps в команде. |
| **Интеграция** | Своя экосистема (Kibana) | Нативная для Grafana | Мы уже используем Grafana для мониторинга. |
| **Скорость поиска** | Очень быстрая по любому слову | Быстрая по лейблам, медленнее по тексту | Для разбора проблем с заказами поиска по `order_id` в Loki достаточно. |
| **Порог входа** | Средний (язык запросов DSL/Lucene) | Низкий (язык LogQL похож на Prometheus) | Команде будет проще начать пользоваться. |

**Итог:** Выбран **Loki**, так как он дешевле, проще в поддержке для одного DevOps-инженера и отлично дополняет уже внедренные метрики.
